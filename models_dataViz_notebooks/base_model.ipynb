{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "base_dir = ''\n",
    "dataset = pd.read_csv(base_dir + 'DEAM_dataset_paths.csv')\n",
    "dataset['file_path'] = dataset['file_path'].str.replace('\\\\', '/')\n",
    "dataset['file_path'] = dataset['file_path']\n",
    "\n",
    "def extract_features(file_path, index):\n",
    "    y, sr = librosa.load(file_path, duration=30)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    tonnetz = librosa.feature.tonnetz(y=y, chroma=chroma, sr=sr)\n",
    "    features = [mfccs, chroma, mel, contrast, tonnetz]\n",
    "    averaged_features = [np.mean(feat, axis=1) for feat in features]\n",
    "    return np.concatenate(averaged_features)\n",
    "\n",
    "features = []\n",
    "for index, row in enumerate(dataset['file_path']):\n",
    "    print(f\"Processing file at index {index}...\")\n",
    "    features.append(extract_features(row, index))\n",
    "\n",
    "features = np.array(features)   \n",
    "np.save('DEAM_extracted_features_base.npy', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = ''\n",
    "dataset = pd.read_csv(base_dir + 'DEAM_dataset_paths.csv')\n",
    "dataset['file_path'] = dataset['file_path'].str.replace('\\\\', '/')\n",
    "dataset['file_path'] = dataset['file_path']\n",
    "\n",
    "features = np.load('DEAM_extracted_features_base.npy')\n",
    "valence = dataset[' valence_mean'].values.astype(np.float32)  \n",
    "arousal = dataset[' arousal_mean'].values.astype(np.float32)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "features_tensor = torch.tensor(features_scaled, dtype=torch.float32)\n",
    "valence_tensor = torch.tensor(valence, dtype=torch.float32)\n",
    "arousal_tensor = torch.tensor(arousal, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class AudioFeaturesDataset(Dataset):    \n",
    "    def __init__(self, features, targets):\n",
    "\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(features_tensor, valence_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = AudioFeaturesDataset(X_train, y_train)\n",
    "test_dataset = AudioFeaturesDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training example features shape: torch.Size([32, 193])\n",
      "Training example label: tensor(4.5000)\n",
      "Validation example features shape: torch.Size([32, 193])\n",
      "Validation example label: tensor(3.8000)\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(\"Training example features shape:\", train_features.shape)\n",
    "print(\"Training example label:\", train_labels[0])\n",
    "\n",
    "val_features, val_labels = next(iter(test_loader))\n",
    "print(\"Validation example features shape:\", val_features.shape)\n",
    "print(\"Validation example label:\", val_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ComplexNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 500)\n",
    "        self.fc2 = nn.Linear(500, 500)\n",
    "        self.fc3 = nn.Linear(500, 500)\n",
    "        self.fc4 = nn.Linear(500, 500)\n",
    "        self.fc5 = nn.Linear(500, 500)\n",
    "        self.fc6 = nn.Linear(500, 500)\n",
    "        self.fc7 = nn.Linear(500, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = torch.relu(self.fc6(x))\n",
    "        x = self.fc7(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1]\n",
    "print(input_shape)\n",
    "valence_model = ComplexNN(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import os\n",
    "from math import sqrt\n",
    "\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets_batch in data_loader:\n",
    "            inputs, targets_batch = inputs.to(device), targets_batch.to(device)  # Move to the specified device\n",
    "            outputs = model(inputs)\n",
    "            predictions.extend(outputs.squeeze().tolist())\n",
    "            targets.extend(targets_batch.tolist())\n",
    "    mse = mean_squared_error(targets, predictions)\n",
    "    rmse = sqrt(mse)\n",
    "    r2 = r2_score(targets, predictions)\n",
    "    return mse, rmse, r2\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, train_loader, test_loader, lr, epochs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    test_mse, test_rmse, test_r2 = evaluate_model(model, test_loader, device = 'cuda')\n",
    "    print(f\"LR: {lr}, Epochs: {epochs}, Test MSE: {test_mse:.4f}, Test RMSE: {test_rmse:.4f}, Test R2: {test_r2:.4f}\")\n",
    "    \n",
    "    model_directory = f\"base_model/\"\n",
    "    if not os.path.exists(model_directory):\n",
    "        os.makedirs(model_directory)\n",
    "    torch.save(model.state_dict(), f\"{model_directory}/model.pth\")\n",
    "    print(f\"Model saved in '{model_directory}/model.pth'\")\n",
    "\n",
    "    return test_mse, test_rmse, test_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.005, Epochs: 120, Test MSE: 0.8677, Test RMSE: 0.9315, Test R2: 0.2353\n",
      "Model saved in 'base_model/grid_search//model.pth'\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "lr =  0.005\n",
    "epochs = 50\n",
    "mse, rmse, r2 = train_and_evaluate(valence_model, train_loader, test_loader, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class AudioFeaturesDataset(Dataset):    \n",
    "    def __init__(self, features, targets):\n",
    "\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(features_tensor, arousal_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = AudioFeaturesDataset(X_train, y_train)\n",
    "test_dataset = AudioFeaturesDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1]\n",
    "print(input_shape)\n",
    "arousal_model = ComplexNN(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.005, Epochs: 100, Test MSE: 1.4920, Test RMSE: 1.2215, Test R2: 0.1665\n",
      "Model saved in 'base_model/grid_search//model.pth'\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "lr =  0.005\n",
    "epochs = 100\n",
    "mse, rmse, r2 = train_and_evaluate(arousal_model, train_loader, test_loader, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.001, Epochs: 30, Test MSE: 0.7429, Test RMSE: 0.8619, Test R2: 0.3453\n",
      "Model saved in 'base_model/grid_search//model.pth'\n",
      "LR: 0.001, Epochs: 50, Test MSE: 0.7510, Test RMSE: 0.8666, Test R2: 0.3381\n",
      "Model saved in 'base_model/grid_search//model.pth'\n",
      "LR: 0.001, Epochs: 100, Test MSE: 0.7064, Test RMSE: 0.8405, Test R2: 0.3774\n",
      "Model saved in 'base_model/grid_search//model.pth'\n",
      "LR: 0.005, Epochs: 30, Test MSE: 0.7867, Test RMSE: 0.8870, Test R2: 0.3067\n",
      "Model saved in 'base_model/grid_search//model.pth'\n",
      "LR: 0.005, Epochs: 50, Test MSE: 0.7882, Test RMSE: 0.8878, Test R2: 0.3054\n",
      "Model saved in 'base_model/grid_search//model.pth'\n",
      "LR: 0.005, Epochs: 100, Test MSE: 0.8266, Test RMSE: 0.9092, Test R2: 0.2716\n",
      "Model saved in 'base_model/grid_search//model.pth'\n",
      "Best MSE: 0.7064342346625143, Configuration: {'lr': 0.001, 'epochs': 100}\n",
      "Best R^2: 0.3774265575739525, Configuration: {'lr': 0.001, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "device = 'cuda'\n",
    "hyperparams_grid = {\n",
    "    'lr': [0.001, 0.005],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "def grid_search_hyperparams(model_class, input_shape, train_loader, test_loader, hyperparams_grid):\n",
    "    best_mse = float('inf')\n",
    "    best_r2 = -float('inf')\n",
    "    best_params_mse = {}\n",
    "    best_params_r2 = {}\n",
    "\n",
    "    combinations = list(itertools.product(*(hyperparams_grid[key] for key in hyperparams_grid)))\n",
    "\n",
    "    for lr, epochs in combinations:\n",
    "        model = model_class(input_shape).to(device)\n",
    "        \n",
    "        mse, rmse, r2 = train_and_evaluate(model, train_loader, test_loader, lr, epochs)\n",
    "\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_params_mse = {'lr': lr, 'epochs': epochs}\n",
    "\n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_params_r2 = {'lr': lr, 'epochs': epochs}\n",
    "\n",
    "    print(f\"Best MSE: {best_mse}, Configuration: {best_params_mse}\")\n",
    "    print(f\"Best R^2: {best_r2}, Configuration: {best_params_r2}\")\n",
    "    \n",
    "grid_search_hyperparams(ComplexNN, input_shape, train_loader, test_loader, hyperparams_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
